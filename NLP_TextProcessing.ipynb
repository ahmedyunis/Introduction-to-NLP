{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "NLP_TextProcessing.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedyunis/Introduction-to-NLP/blob/main/NLP_TextProcessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy8iYp5MFq5N",
        "outputId": "8762666c-ab58-4118-a94f-56ab0f3d1e60"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P0ixvILFfw3",
        "outputId": "b1b9f671-e75b-43e7-f157-e4be52bb09aa"
      },
      "source": [
        "##tokenization\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "text = \"Hi John, How are you doing ? I will be travelling to your city. Lets Catchup\"\n",
        "#capture sentences with a text\n",
        "sent_tokenize(text)\n",
        "\n",
        "#capture words \n",
        "word_tokenize(text)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi',\n",
              " 'John',\n",
              " ',',\n",
              " 'How',\n",
              " 'are',\n",
              " 'you',\n",
              " 'doing',\n",
              " '?',\n",
              " 'I',\n",
              " 'will',\n",
              " 'be',\n",
              " 'travelling',\n",
              " 'to',\n",
              " 'your',\n",
              " 'city',\n",
              " '.',\n",
              " 'Lets',\n",
              " 'Catchup']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcRm5LH7Ffw3",
        "outputId": "09c0df9d-c48e-429c-ec5e-e79f2816d711"
      },
      "source": [
        "#stemming  #one of normalization familly \r\n",
        "\r\n",
        "from nltk.stem import PorterStemmer\r\n",
        "\r\n",
        "#create an Object of class\r\n",
        "stemmer = PorterStemmer()\r\n",
        "\r\n",
        "print(stemmer.stem(\"playing\"))\r\n",
        "print(stemmer.stem(\"plays\"))\r\n",
        "print(stemmer.stem(\"played\"))\r\n",
        "\r\n",
        "#however stemming  is not very good Normalization process because it some times  produce words out of the dictionary \r\n",
        "\r\n",
        "print(stemmer.stem(\"increases\"))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "play\n",
            "play\n",
            "play\n",
            "increas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4rtW66HKCWf",
        "outputId": "18fe2079-c326-4475-f8d1-c7228a205284"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7QNoEnmFfw4",
        "outputId": "a29e0824-05da-44dd-b0a8-9d2f895a7b58"
      },
      "source": [
        "#Lemmatization its more efficient way for Normalization\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "\r\n",
        "lemm = WordNetLemmatizer()\r\n",
        "\r\n",
        "print(lemm.lemmatize(\"increases\"))\r\n",
        "print(lemm.lemmatize(\"running\"))\r\n",
        "print(lemm.lemmatize(\"running\", pos='v'))\r\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "increase\n",
            "running\n",
            "run\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGexP1cQK9rs",
        "outputId": "9b9c6616-e890-464a-f32e-a9f820d789ae"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnPTKErrJ87m",
        "outputId": "ce3a9df2-56c1-4a84-9ebf-ea4bdf78e0a9"
      },
      "source": [
        "#Part of Speech Tags\r\n",
        "from nltk import pos_tag\r\n",
        "\r\n",
        "text1 = \"Hi John, How are you doing ? I will be travelling to your city. Lets Catchup\"\r\n",
        "\r\n",
        "tokens = word_tokenize(text1)\r\n",
        "\r\n",
        "pos_tag(tokens)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Hi', 'NNP'),\n",
              " ('John', 'NNP'),\n",
              " (',', ','),\n",
              " ('How', 'NNP'),\n",
              " ('are', 'VBP'),\n",
              " ('you', 'PRP'),\n",
              " ('doing', 'VBG'),\n",
              " ('?', '.'),\n",
              " ('I', 'PRP'),\n",
              " ('will', 'MD'),\n",
              " ('be', 'VB'),\n",
              " ('travelling', 'VBG'),\n",
              " ('to', 'TO'),\n",
              " ('your', 'PRP$'),\n",
              " ('city', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Lets', 'VBZ'),\n",
              " ('Catchup', 'NNP')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1ElP5oqK3T5",
        "outputId": "a71025c3-2214-4bdf-c037-c870c2660a5a"
      },
      "source": [
        "from nltk.corpus import wordnet\r\n",
        "\r\n",
        "wordnet.synsets(\"good\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('good.n.01'),\n",
              " Synset('good.n.02'),\n",
              " Synset('good.n.03'),\n",
              " Synset('commodity.n.01'),\n",
              " Synset('good.a.01'),\n",
              " Synset('full.s.06'),\n",
              " Synset('good.a.03'),\n",
              " Synset('estimable.s.02'),\n",
              " Synset('beneficial.s.01'),\n",
              " Synset('good.s.06'),\n",
              " Synset('good.s.07'),\n",
              " Synset('adept.s.01'),\n",
              " Synset('good.s.09'),\n",
              " Synset('dear.s.02'),\n",
              " Synset('dependable.s.04'),\n",
              " Synset('good.s.12'),\n",
              " Synset('good.s.13'),\n",
              " Synset('effective.s.04'),\n",
              " Synset('good.s.15'),\n",
              " Synset('good.s.16'),\n",
              " Synset('good.s.17'),\n",
              " Synset('good.s.18'),\n",
              " Synset('good.s.19'),\n",
              " Synset('good.s.20'),\n",
              " Synset('good.s.21'),\n",
              " Synset('well.r.01'),\n",
              " Synset('thoroughly.r.02')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvFNhH_dLi8K",
        "outputId": "fd111c5e-9365-4d17-a989-3d0a49fec38c"
      },
      "source": [
        "wordnet.synsets(\"computer\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('computer.n.01'), Synset('calculator.n.01')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Skyd10ZL3vt",
        "outputId": "31d07130-97b4-41a1-ab9b-e0a8afbdd7a9"
      },
      "source": [
        "from nltk import  ngrams\r\n",
        "sentence = \"I love to watch Football\"\r\n",
        "\r\n",
        "n = 2\r\n",
        "for gram in ngrams(word_tokenize(sentence), n ):\r\n",
        "  print(gram)\r\n",
        "\r\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('I', 'love')\n",
            "('love', 'to')\n",
            "('to', 'watch')\n",
            "('watch', 'Football')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kRaD2GqMB5W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}