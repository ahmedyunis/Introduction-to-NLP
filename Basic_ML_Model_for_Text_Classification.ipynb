{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Basic ML Model for Text Classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPTqvKGoq+hWmVOzfQuNPJw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedyunis/Introduction-to-NLP/blob/main/Basic_ML_Model_for_Text_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpO1hfALQ0tn"
      },
      "source": [
        "Build a machine learning model to classify whether a particular tweet is hate speech or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWjhzfXjQ_G1"
      },
      "source": [
        "# About the Dataset\r\n",
        "\r\n",
        "Used for **Detecting Hate Speech** in people's tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "YuV7yvaCQAOr",
        "outputId": "baf37b83-6ffe-462c-f2f3-cbef5f2068a3"
      },
      "source": [
        "#Load the Dataset \r\n",
        "import pandas as pd \r\n",
        "\r\n",
        "dataset = pd.read_csv(\"/content/final_dataset_basicmlmodel.csv\")\r\n",
        "dataset.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet\n",
              "0   1      0   @user when a father is dysfunctional and is s...\n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
              "2   3      0                                bihday your majesty\n",
              "3   4      0  #model   i love u take with u all the time in ...\n",
              "4   5      0             factsguide: society now    #motivation"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w89Lngx-Q-jY",
        "outputId": "fc52e7b6-60c1-4264-f450-cf2d32d6a057"
      },
      "source": [
        "for index, tweet in enumerate(dataset[\"tweet\"][10:15]):\r\n",
        "    print(index+1,\".\",tweet)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 .  â #ireland consumer price index (mom) climbed from previous 0.2% to 0.5% in may   #blog #silver #gold #forex\n",
            "2 . we are so selfish. #orlando #standwithorlando #pulseshooting #orlandoshooting #biggerproblems #selfish #heabreaking   #values #love #\n",
            "3 . i get to see my daddy today!!   #80days #gettingfed\n",
            "4 . ouch...junior is angryð#got7 #junior #yugyoem   #omg \n",
            "5 . i am thankful for having a paner. #thankful #positive     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6QccvuEUuhn"
      },
      "source": [
        "**Noise present in Tweets** \r\n",
        "\r\n",
        "hashtags # , strange sympoles ,  numerals and percentages \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_2c6JACVLMF"
      },
      "source": [
        "#Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rCgLXjJUhvT"
      },
      "source": [
        "import re \r\n",
        "\r\n",
        "#clean text from noise \r\n",
        "def Clean_text(text):\r\n",
        "  #filter to allow only alphapets\r\n",
        "  text = re.sub(r'[^a-zA-Z\\']',' ',text)\r\n",
        "\r\n",
        "  #remove unicode characters \r\n",
        "  text = re.sub(r'[^\\x00-\\x7F]+', ' ',text)\r\n",
        "\r\n",
        "  #convert to lowercase to maintain consistency \r\n",
        "  text =text.lower()\r\n",
        "\r\n",
        "  return text\r\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_QgmRKfVSO1"
      },
      "source": [
        "dataset[\"clean_text\"] = dataset.tweet.apply(lambda x: Clean_text(x))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "VSLGEvRtXMqq",
        "outputId": "48fc7d58-6ea6-4868-b2d0-a071dc08811e"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>user  user thanks for  lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide  society now     motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                         clean_text\n",
              "0   1  ...    user when a father is dysfunctional and is s...\n",
              "1   2  ...   user  user thanks for  lyft credit i can't us...\n",
              "2   3  ...                                bihday your majesty\n",
              "3   4  ...   model   i love u take with u all the time in ...\n",
              "4   5  ...             factsguide  society now     motivation\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O913Uu26XiFe"
      },
      "source": [
        "#Feature Engineering\r\n",
        "\r\n",
        "extracting more information from existing data, making the data you already have more useful"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBkD5zfNXWLz"
      },
      "source": [
        "#Exhaustive list of stopwords in the english language. We want to focus less on these so at some point will have to filter\r\n",
        "\r\n",
        "STOP_WORDS = ['a', 'about', 'above', 'after', 'again', 'against', 'all', 'also', 'am', 'an', 'and',\r\n",
        "              'any', 'are', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below',\r\n",
        "              'between', 'both', 'but', 'by', 'can', \"can't\", 'cannot', 'com', 'could', \"couldn't\", 'did',\r\n",
        "              \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during', 'each', 'else', 'ever',\r\n",
        "              'few', 'for', 'from', 'further', 'get', 'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having',\r\n",
        "              'he', \"he'd\", \"he'll\", \"he's\", 'her', 'here', \"here's\", 'hers', 'herself', 'him', 'himself', 'his', 'how',\r\n",
        "              \"how's\", 'however', 'http', 'i', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it',\r\n",
        "              \"it's\", 'its', 'itself', 'just', 'k', \"let's\", 'like', 'me', 'more', 'most', \"mustn't\", 'my', 'myself',\r\n",
        "              'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'otherwise', 'ought', 'our', 'ours',\r\n",
        "              'ourselves', 'out', 'over', 'own', 'r', 'same', 'shall', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\",\r\n",
        "              'should', \"shouldn't\", 'since', 'so', 'some', 'such', 'than', 'that', \"that's\", 'the', 'their', 'theirs',\r\n",
        "              'them', 'themselves', 'then', 'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\", \"they're\",\r\n",
        "              \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was', \"wasn't\",\r\n",
        "              'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\", 'when', \"when's\", 'where',\r\n",
        "              \"where's\", 'which', 'while', 'who', \"who's\", 'whom', 'why', \"why's\", 'with', \"won't\", 'would', \"wouldn't\",\r\n",
        "              'www', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdCTuHJJZIiH"
      },
      "source": [
        "#Generate Word Frequancy \r\n",
        "def gen_freq(text):\r\n",
        "  #list to store the words\r\n",
        "  words_list = []\r\n",
        "\r\n",
        "  #loop over all the tweets and extract words into listof words \r\n",
        "  for word in text.split():\r\n",
        "    words_list.extend(word)\r\n",
        "\r\n",
        "  #create word frequances \r\n",
        "  word_freq = pd.Series(words_list).value_counts()\r\n",
        "\r\n",
        "  #Drop the stop words  \r\n",
        "  word_freq = word_freq.drop(STOP_WORDS, errors='ignore')\r\n",
        "\r\n",
        "  return word_freq\r\n",
        "\r\n",
        "#Check whether a negation term is present in the text\r\n",
        "def any_neg(words):\r\n",
        "    for word in words:\r\n",
        "        if word in ['n', 'no', 'non', 'not'] or re.search(r\"\\wn't\", word):\r\n",
        "            return 1\r\n",
        "    else:\r\n",
        "        return 0\r\n",
        "\r\n",
        "#Check whether one of the 100 rare words is present in the text\r\n",
        "def any_rare(words, rare_100):\r\n",
        "    for word in words:\r\n",
        "        if word in rare_100:\r\n",
        "            return 1\r\n",
        "    else:\r\n",
        "        return 0\r\n",
        "\r\n",
        "#Check whether prompt words are present\r\n",
        "def is_question(words):\r\n",
        "    for word in words:\r\n",
        "        if word in ['when', 'what', 'how', 'why', 'who']:\r\n",
        "            return 1\r\n",
        "    else:\r\n",
        "        return 0 "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjziM1bDbYCH"
      },
      "source": [
        "word_freq = gen_freq(dataset.clean_text.str)\r\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1J6Oy6Fbb1M"
      },
      "source": [
        "#100 most rare words in the dataset\r\n",
        "#100 most rare words in the dataset\r\n",
        "rare_100 = word_freq[-100:]\r\n",
        "\r\n",
        "#Number of words in a tweet\r\n",
        "dataset['word_count'] = dataset.clean_text.str.split().apply(lambda x: len(x))\r\n",
        "\r\n",
        "#Negation present or not\r\n",
        "dataset['any_neg'] = dataset.clean_text.str.split().apply(lambda x: any_neg(x))\r\n",
        "\r\n",
        "#Prompt present or not\r\n",
        "dataset['is_question'] = dataset.clean_text.str.split().apply(lambda x: is_question(x))\r\n",
        "\r\n",
        "#Any of the most 100 rare words present or not\r\n",
        "dataset['any_rare'] = dataset.clean_text.str.split().apply(lambda x: any_rare(x, rare_100))\r\n",
        "\r\n",
        "#Character count of the tweet\r\n",
        "dataset['char_count'] = dataset.clean_text.apply(lambda x: len(x))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVrEKxK6cJV5",
        "outputId": "7aad1cdc-3721-4999-a6a4-e0eb2270b148"
      },
      "source": [
        "#Top 10 common words are\r\n",
        "gen_freq(dataset.clean_text.str)[:10]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "user      3351\n",
              "amp        439\n",
              "love       320\n",
              "day        254\n",
              "trump      214\n",
              "happy      207\n",
              "will       191\n",
              "people     186\n",
              "new        171\n",
              "u          158\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "mufqw74IcMYN",
        "outputId": "688586aa-4a07-44fb-e9ae-5a3f433b6be6"
      },
      "source": [
        "dataset.head()\r\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>word_count</th>\n",
              "      <th>any_neg</th>\n",
              "      <th>is_question</th>\n",
              "      <th>any_rare</th>\n",
              "      <th>char_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>user when a father is dysfunctional and is s...</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>user  user thanks for  lyft credit i can't us...</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model   i love u take with u all the time in ...</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide  society now     motivation</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label  ... any_rare char_count\n",
              "0   1      0  ...        0        102\n",
              "1   2      0  ...        0        122\n",
              "2   3      0  ...        0         21\n",
              "3   4      0  ...        0         86\n",
              "4   5      0  ...        0         39\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_vj8JRNcaLu"
      },
      "source": [
        "#Splitting the dataset into Train-Test split\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSx1Aa7McPgB"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X = dataset[['word_count', 'any_neg', 'any_rare', 'char_count', 'is_question']]\r\n",
        "\r\n",
        "y = dataset.label\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=27)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Luuex2ppdYmv"
      },
      "source": [
        "#**Train an ML model for Text Classification**\r\n",
        "\r\n",
        "using a **Naive Bayes** classifier from sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn6nDkzGdXK1"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "\r\n",
        "#Initialize GaussianNB classifier\r\n",
        "model = GaussianNB()\r\n",
        "\r\n",
        "#Fit the model on the train dataset\r\n",
        "model = model.fit(X_train, y_train)\r\n",
        "\r\n",
        "#Make predictions on the test dataset\r\n",
        "pred = model.predict(X_test)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isEvw8lfd1uX"
      },
      "source": [
        "**Evaluate the ML model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUSLcDV5dwYy",
        "outputId": "921dcd6d-ad53-466f-8e77-7a8eddbcd5ab"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "print(\"Accuracy:\", accuracy_score(y_test, pred)*100, \"%\")\r\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 60.1904761904762 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPqT-1sFeEN-"
      },
      "source": [
        "since we have used very basic NLP features, the classification accuracy and f1 scores aren't that impressive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzxE-Lbmd6ei"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}